{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.read_csv('tweets.csv')\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data precrocessing and cleaning\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet = WordNetLemmatizer()\n",
    "corpus = []\n",
    "for i in range(0,len(tweets)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ',tweets['tweet'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the bagsof model \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 34000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = tweets['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "hate_speech_detect = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Resources/TweetBrain','wb') as f:\n",
    "    pickle.dump(hate_speech_detect,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=hate_speech_detect.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5846  139]\n",
      " [ 172  236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      5985\n",
      "           1       0.63      0.58      0.60       408\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.80      0.78      0.79      6393\n",
      "weighted avg       0.95      0.95      0.95      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "confusion_m = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_m)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9513530423901142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = [\"This shit geat is nothing but a camouflage #Vanity event for the OrangeBigot & his Nazis ! #HATE disgraceful placed in front of the #LincolnMemorial how MORE of a POScan he show us he is ?! This shit has NOTHING TO DO WITH #PATROITIC ways as Rump is TREASON period ! \"]\n",
    "#tweets = [\"I had a GREAT week,thanks to YOU! If you need anything, please reach out.\"]\n",
    "try :\n",
    "    tweets =[\"This shit geat is nothing but a camouflage #Vanity event for the OrangeBigot & his Nazis ! #HATE disgraceful placed in front of the #LincolnMemorial how MORE of a POScan he show us he is ?! This shit has NOTHING TO DO WITH #PATROITIC ways as Rump is TREASON period ! \"]\n",
    "    df =pd.DataFrame(data = tweets,columns = [\"tweet\"])\n",
    "    lis = []\n",
    "    for i in range(0,len(tweets)):\n",
    "        review = re.sub('[^a-zA-Z]', ' ',df['tweet'][i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "    \n",
    "        review = [wordnet.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        lis.append(review)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "Your Text is Hateful!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    inp=[]\n",
    "    feat=cv.get_feature_names()\n",
    "    dim=\"\"\n",
    "    for item in feat:\n",
    "        dim+=item+\" \"\n",
    "    inp.append(dim)\n",
    "#Saving the content of unique words\n",
    "    featurefile=open('Resources/featurefile.txt','w')\n",
    "    featurefile.write(dim)\n",
    "    featurefile.close()\n",
    "    \n",
    "    inp.append(*lis)\n",
    "    predictionset=cv.fit_transform(inp).toarray()\n",
    "    #print(predictionset)\n",
    "    y_predion=hate_speech_detect.predict(predictionset)\n",
    "    print(y_predion)\n",
    "    if y_predion[1] == 1:\n",
    "        print(\"Your Text is Hateful!\")\n",
    "    else:\n",
    "        print(\"Your Text is neutral!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This shit geat is nothing but a camouflage #Vanity \n",
    "event for the OrangeBigot & his Nazis ! #HATE disgraceful placed in front of the #LincolnMemorial how MORE of a POScan he show us he is ?! This shit has NOTHING TO DO WITH #PATROITIC ways as Rump is TREASON period ! pic.twitter.com/7VFvskmIQg\n",
    "\n",
    "Edward Parkins and your obsession with #hate and #bigotry like itâ€™s some sort of kryptonite for you in #attacking these 2 human beings no longer a part of your cult. Your attempt corrupt their character in s court of law is a lost cause. End this or your account is banned!\n",
    "\n",
    "Taj Mohammad, 17, was beaten up by unidentified bike-borne youths in Kanpur (UP). Assailants forced him to chant the slogan, Jai Shri Ram. They assaulted him, pushed him down on the road, punched & kicked him. Incident on June 28, 2019.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
